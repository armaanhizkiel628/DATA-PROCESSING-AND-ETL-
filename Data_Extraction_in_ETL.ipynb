{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 : Describe different types of data sources used in ETL with suitable examples.\n",
        "\n",
        "ANSWER 1\n",
        "1. ETL uses data from different sources to collect and store information in one place\n",
        "\n",
        "* DATABASE = These are structured sources where data is stored in tables.\n",
        "\n",
        "*  Flat file = Data stored in text format. Example: CSV files, text files.\n",
        "\n",
        "* spreadsheet = Used to store data manually or for reports. Example: Excel sheets.\n",
        "\n",
        "* cloud storage = it Data stored online. Example: Amazon S3, Google Cloud Storage."
      ],
      "metadata": {
        "id": "lYCTT205toCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 : What is data extraction? Explain its role in the ETL pipeline\n",
        "\n",
        "answer 2.\n",
        "\n",
        "1. Data extraction is the first step of the ETL process. It means collecting data from different source systems such as databases, files, or websites.\n",
        "\n",
        "2. Role of Data Extraction in the ETL Pipeline\n",
        "* It pulls data from various sources like databases, Excel files, and APIs.\n",
        "\n",
        "* It ensures the original data is not changed while being extracted.\n",
        "\n",
        "* It helps gather data from multiple systems into one place.\n",
        "\n"
      ],
      "metadata": {
        "id": "OfLxXg_qu5Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 : Explain the difference between CSV and Excel in terms of extraction and ETL usage.\n",
        "\n",
        "answer  3\n",
        "\n",
        "1. Difference Between CSV and Excel in ETL\n",
        "\n",
        "2. csv\n",
        "* file = plain text file\n",
        "* structure = Simple rows and columns\n",
        "* extraction = Easy and fast to extract\n",
        "* data size = Handles large data easily\n",
        "* formatting = no format\n",
        "\n",
        "3. excel  \n",
        "* file = spreadsheet\n",
        "* structure = Rows, columns, multiple sheets\n",
        "* extraction = Slightly complex to extract\n",
        "* data size = Slower with large data\n",
        "* formatting = Used for small or manual data"
      ],
      "metadata": {
        "id": "mtKhS25dvM_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4 : Explain the steps involved in extracting data from a relational database\n",
        "\n",
        "answer 4\n",
        "\n",
        "*  steps Involved in Extracting Data from a Relational Database\n",
        "\n",
        "1. identify the Data Source = First, decide which database is needed, such as MySQL or Oracle, and identify the required tables and columns.\n",
        "\n",
        "2. establish Connection = Create a connection to the database using login details like username, password, and server name.\n",
        "\n",
        "3. select Required Data = Write SQL queries to select only the necessary data from tables.\n",
        "\n",
        "4. Extract the Data = Run the query and extract the data from the database without changing the original data\n",
        "\n",
        "5. Store Extracted Data = save the extracted data in a staging area or temporary storage for further processing.\n",
        "\n",
        "6. Validate the Data = Check the extracted data for missing values or errors before moving to the transformation step"
      ],
      "metadata": {
        "id": "W0Uf67o6wkSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 : Explain three common challenges faced during data extraction\n",
        "\n",
        "answer 5\n",
        "\n",
        "*  Three Common Challenges During Data Extraction\n",
        "1. Data Quality Issues = Source data may contain missing values, duplicate records, or incorrect data, which affects the extraction process.\n",
        "\n",
        "2. Different Data Formats = Data comes from multiple sources like databases, files, and APIs, each having different formats, making extraction difficult.\n",
        "\n",
        "3. Performance Problems = Extracting large amounts of data can slow down source systems or take a long time to complete.\n"
      ],
      "metadata": {
        "id": "b_NWfvOEynEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6 : What are APIs? Explain how APIs help in real-time data extraction.\n",
        "answer\n",
        "\n",
        "1. APIs = Application Programming Interfaces  are rules that allow different software applications to communicate with each other. They let one system request data and another system send it.\n",
        "\n",
        "2. How APIs Help in Real-Time Data Extraction\n",
        "\n",
        "* APIs allow instant access to live data from applications.\n",
        "\n",
        "* Data can be extracted whenever it is updated, ensuring freshness.\n",
        "\n",
        "* They support automatic and continuous data extraction.\n",
        "\n",
        "* APIs reduce the need for manual file transfers.\n",
        "\n",
        "* They are commonly used for web and cloud-based applications."
      ],
      "metadata": {
        "id": "q2eMgnJG0Blk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7 : Why are databases preferred for enterprise-level data extraction?\n",
        "\n",
        "answer 7\n",
        "\n",
        "1. Databases can handle very large amounts of data efficiently.\n",
        "\n",
        "2. They provide high performance and fast access to data.\n",
        "\n",
        "3. Databases ensure data accuracy and consistency.\n",
        "\n",
        "4. They support secure access with authentication and permissions.\n",
        "\n",
        "5. They allow easy integration with ETL tools using SQL queries."
      ],
      "metadata": {
        "id": "Y_swt99U0qJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8 : What steps should an ETL developer take when extracting data from large CSV files (1GB+)?\n",
        "\n",
        "answer\n",
        "\n",
        "* Steps for Extracting Data from Large CSV Files 1GB\n",
        "\n",
        "1. Check File Structure\n",
        "\n",
        "Understand the number of columns, delimiter used, and data types before extraction.\n",
        "\n",
        "2. Use Chunk or Batch Processing\n",
        "\n",
        "Read the file in small chunks instead of loading the entire file at once to avoid memory issues.\n",
        "\n",
        "3. Compress or Split the File\n",
        "\n",
        "Split large CSV files into smaller parts if possible for easier processing.\n",
        "\n",
        "4. Use Staging Area\n",
        "\n",
        "Load the data into a staging table or temporary storage before transformation.\n",
        "\n",
        "5. Validate Data During Extraction\n",
        "\n",
        "Check for missing values, duplicates, or incorrect records while extracting.\n",
        "\n",
        "6. Optimize ETL Tool Settings\n",
        "\n",
        "Tune buffer size, parallel processing, and file read options for better performance"
      ],
      "metadata": {
        "id": "WJk4LUnm1DOO"
      }
    }
  ]
}